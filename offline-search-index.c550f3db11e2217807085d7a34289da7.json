




















































[{"body":"本页为您介绍 KLTS 的 Kubernetes 版本支持机制。\n如图所示，V1.16.15 是 Kubernetes 的完整发行版本号，其中 1.16 是大版本号，15 是社区补丁版本，而 lts.0 是 KLTS 的补丁版本号。\n上图以 2021 年 8 月 31 日的最新版本 1.22 为例，Kubernetes 社区仅维护 1.19 – 1.22 四个版本。而 KLTS 则提供从 1.10 到 1.18 的版本维护，每个版本的支持周期至少两年。其中 Kubernetes 1.10 是 DaoCloud Enterprise 3.0 的生产内核，其维护周期会相对更长。我们会将修复 bug 后的稳定版本上传至 KLTS，供社区下载使用。\nKubernetes 社区一般每隔 4 个月左右发布一个大版本，KLTS 维护的 Kubernetes 版本也会随之变化。通常在 Kubernetes 社区停止维护某个版本后的一个月内，KLTS 将开始维护刚被社区停止维护的版本。\n例如，如果社区正式发布 1.23 版本，KLTS 维护的版本也会加一，达到 1.19，以此类推。KLTS 的补丁更新频率将根据实际解决的 bug 情况发布。\n","categories":"","description":"","excerpt":"本页为您介绍 KLTS 的 Kubernetes 版本支持机制。\n如图所示，V1.16.15 是 Kubernetes 的完整发行版本号，其 …","ref":"/zh/docs/intro/","tags":"","title":"简介"},{"body":"This page shows how to install the kubeadm toolbox. For information on how to create a cluster with kubeadm once you have performed this installation process, see the Using kubeadm to Create a Cluster page.\nBefore you begin  A compatible Linux host. The Kubernetes project provides generic instructions for Linux distributions based on Debian and Red Hat, and those distributions without a package manager. 2 GB or more of RAM per machine (any less will leave little room for your apps). 2 CPUs or more. Full network connectivity between all machines in the cluster (public or private network is fine). Unique hostname, MAC address, and product_uuid for every node. See here for more details. Certain ports are open on your machines. See here for more details. Swap disabled. You MUST disable swap in order for the kubelet to work properly.  Verify the MAC address and product_uuid are unique for every node  You can get the MAC address of the network interfaces using the command ip link or ifconfig -a The product_uuid can be checked by using the command sudo cat /sys/class/dmi/id/product_uuid  It is very likely that hardware devices will have unique addresses, although some virtual machines may have identical values. Kubernetes uses these values to uniquely identify the nodes in the cluster. If these values are not unique to each node, the installation process may fail.\nCheck network adapters If you have more than one network adapter, and your Kubernetes components are not reachable on the default route, we recommend you add IP route(s) so Kubernetes cluster addresses go via the appropriate adapter.\nLetting iptables see bridged traffic Make sure that the br_netfilter module is loaded. This can be done by running lsmod | grep br_netfilter. To load it explicitly call sudo modprobe br_netfilter.\nAs a requirement for your Linux Node’s iptables to correctly see bridged traffic, you should ensure net.bridge.bridge-nf-call-iptables is set to 1 in your sysctl config, e.g.\ncat \u003c\u003cEOF | sudo tee /etc/modules-load.d/k8s.conf br_netfilter EOF cat \u003c\u003cEOF | sudo tee /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 EOF sudo sysctl --system For more details please see the Network Plugin Requirements page.\nCheck required ports Control-plane node(s)    Protocol Direction Port Range Purpose Used By     TCP Inbound 6443* Kubernetes API server All   TCP Inbound 2379-2380 etcd server client API kube-apiserver, etcd   TCP Inbound 10250 kubelet API Self, Control plane   TCP Inbound 10251 kube-scheduler Self   TCP Inbound 10252 kube-controller-manager Self    Worker node(s)    Protocol Direction Port Range Purpose Used By     TCP Inbound 10250 kubelet API Self, Control plane   TCP Inbound 30000-32767 NodePort Services† All    † Default port range for NodePort Services.\nAny port numbers marked with * are overridable, so you will need to ensure any custom ports you provide are also open.\nAlthough etcd ports are included in control-plane nodes, you can also host your own etcd cluster externally or on custom ports.\nThe pod network plugin you use (see below) may also require certain ports to be open. Since this differs with each pod network plugin, please see the documentation for the plugins about what port(s) those need.\nSetting node name hostnamectl set-hostname your-new-host-name echo \"127.0.0.1 $(hostname)\" \u003e\u003e /etc/hosts echo \"::1 $(hostname)\" \u003e\u003e /etc/hosts Disable Swap swapoff -a If you want to disable swap permanently, edit the /etc/fstab file to comment out the swap mount\nDisable Selinux setenforce 0 If you want to disable selinux permanently, edit /etc/sysconfig/selinux and replace SELINUX=enforcing with SELINUX=disabled\nInstall Runtime To run containers in Pods, Kubernetes uses a Container Runtime Interface (Container Runtime)\nLinux Node 其它操作系统 By default, Kubernetes uses the Container Runtime Interface (CRI) to interface with your chosen container runtime.\nIf you don’t specify a runtime, kubeadm automatically tries to detect an installed container runtime by scanning through a list of well known Unix domain sockets. The following table lists container runtimes and their associated socket paths:\n   Runtime Path to Unix domain socket     Docker /var/run/dockershim.sock   Containerd /run/containerd/containerd.sock   CRI-O /var/run/crio/crio.sock     If both Docker and containerd are detected, Docker takes precedence. This is needed because Docker 18.09 ships with containerd and both are detectable even if you only installed Docker. If any other two or more runtimes are detected, kubeadm exits with an error. The kubelet integrates with Docker through the built-in dockershim CRI implementation.\n By default, kubeadm uses Docker as the container runtime. The kubelet integrates with Docker through the built-in dockershim CRI implementation.\n Docker Containerd  Red Hat-based distributions Debian-based distributions yum install docker  apt-get install docker.io   VERSION=1.5.4 wget -c https://github.com/containerd/containerd/releases/download/v${VERSION}/containerd-${VERSION}-linux-amd64.tar.gz tar xvf containerd-${VERSION}-linux-amd64.tar.gz -C /usr/local/ mkdir /etc/containerd/ \u0026\u0026 containerd config default \u003e /etc/containerd/config.toml wget -c -O /etc/systemd/system/containerd.service https://raw.githubusercontent.com/containerd/containerd/main/containerd.service systemctl start containerd \u0026\u0026 systemctl enable containerd  See container runtimes for more information.\n","categories":"","description":"","excerpt":"This page shows how to install the kubeadm toolbox. For information on …","ref":"/docs/pre-install/","tags":"","title":"Pre Install"},{"body":"本页介绍如何安装 kubeadm 工具箱。 有关在执行此安装过程后如何使用 kubeadm 创建集群的信息，请参见使用 kubeadm 创建集群。\n准备工作  准备一台兼容的 Linux 主机。Kubernetes 项目为基于 Debian 和 Red Hat 的 Linux 发行版以及一些不提供包管理器的发行版提供通用的指令 每台主机至少 2 GB 或更多的内存（如果内存太少将影响应用的运行） CPU 2 核或更多 集群中所有主机的网络连通（公网和内网） 单个节点上不能有重复的主机名、MAC 地址或 product_uuid，请参阅确保每个节点上 MAC 地址和 product_uuid 的唯一性。 开启主机上的某些端口，请参阅检查所需端口。 禁用交换分区。为了保证 kubelet 正常工作，您必须禁用交换分区。  确保每个节点上 MAC 地址和 product_uuid 的唯一性   你可以使用命令 ip link 或 ifconfig -a 来获取网络接口的 MAC 地址 可以使用 sudo cat /sys/class/dmi/id/product_uuid 命令对 product_uuid 校验  一般来讲，硬件设备会拥有唯一的地址，但是有些虚拟机的地址可能会重复。 Kubernetes 使用这些值来唯一确定集群中的节点。 如果这些值在每个节点上不唯一，可能会导致安装 失败。\n检查网络适配器 如果你有一个以上的网络适配器，同时你的 Kubernetes 组件通过默认路由不可达，我们建议你预先添加 IP 路由规则，这样 Kubernetes 集群就可以通过对应的适配器完成连接。\n允许 iptables 检查桥接流量 确保 br_netfilter 模块被加载。这一操作可以通过运行 lsmod | grep br_netfilter 来完成。若要显式加载该模块，可执行 sudo modprobe br_netfilter。\n为了让你的 Linux 节点上的 iptables 能够正确地查看桥接流量，你需要确保在你的 sysctl 配置中将 net.bridge.bridge-nf-call-iptables 设置为 1。例如：\ncat \u003c\u003cEOF | sudo tee /etc/modules-load.d/k8s.conf br_netfilter EOF cat \u003c\u003cEOF | sudo tee /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 EOF sudo sysctl --system 更多的相关细节可查看网络插件需求页面。\n检查所需端口 控制平面节点    协议 方向 端口范围 作用 使用者     TCP 入站 6443 Kubernetes API 服务器 所有组件   TCP 入站 2379-2380 etcd 服务器客户端 API kube-apiserver, etcd   TCP 入站 10250 Kubelet API kubelet 自身、控制平面组件   TCP 入站 10251 kube-scheduler kube-scheduler 自身   TCP 入站 10252 kube-controller-manager kube-controller-manager 自身    工作节点    协议 方向 端口范围 作用 使用者     TCP 入站 10250 Kubelet API kubelet 自身、控制平面组件   TCP 入站 30000-32767 NodePort 服务† 所有组件    NodePort 服务 的默认端口范围。\n使用 * 标记的任意端口号都可以被覆盖，所以你需要保证所定制的端口是开放的。\n虽然控制平面节点已经包含了 etcd 的端口，你也可以使用自定义的外部 etcd 集群，或是指定自定义端口。\n你使用的 Pod 网络插件 (见下) 也可能需要某些特定端口开启。由于各个 Pod 网络插件都有所不同， 请参阅他们各自文档中对端口的要求。\n设置节点名字 hostnamectl set-hostname your-new-host-name echo \"127.0.0.1 $(hostname)\" \u003e\u003e /etc/hosts echo \"::1 $(hostname)\" \u003e\u003e /etc/hosts 关闭 Swap swapoff -a 如需要永久关闭请编辑 /etc/fstab 文件注释掉 swap 的挂载\n关闭 Selinux setenforce 0 如需要永久关闭请编辑 /etc/sysconfig/selinux 把 SELINUX=enforcing 替换为 SELINUX=disabled\n安装 runtime 为了在 Pod 中运行容器，Kubernetes 使用 容器运行时（Container Runtime）\nLinux 节点 其它操作系统 默认情况下，Kubernetes 使用 容器运行时接口（Container Runtime Interface，CRI） 来与你所选择的容器运行时交互。\n如果你不指定运行时，则 kubeadm 会自动尝试检测到系统上已经安装的运行时， 方法是扫描一组众所周知的 Unix 域套接字。 下面的表格列举了一些容器运行时及其对应的套接字路径：\n   运行时 域套接字     Docker /var/run/dockershim.sock   Containerd /run/containerd/containerd.sock   CRI-O /var/run/crio/crio.sock     如果同时检测到 Docker 和 containerd，则优先选择 Docker。 这是必然的，因为 Docker 18.09 附带了 containerd 并且两者都是可以检测到的， 即使你仅安装了 Docker。 如果检测到其他两个或多个运行时，kubeadm 输出错误信息并退出。 kubelet 通过内置的 dockershim CRI 实现与 Docker 集成。\n 默认情况下， kubeadm 使用 docker 作为容器运行时。 kubelet 通过内置的 dockershim CRI 实现与 Docker 集成。\n Docker Containerd  基于 Red Hat 的发行版 基于 Debian 的发行版 yum install docker  apt-get install docker.io   containerd 官方默认只提供了 amd64 架构的下载包，如果你是其他基础架构的机器， 可以从官方 Docker 仓库安装 containerd.io 软件包。可以在 安装 Docker 引擎 中 找到有关为各自的 Linux 发行版设置 Docker 存储库和安装 containerd.io 软件包的说明。 也可以使用源代码构建。\nVERSION=1.5.4 wget -c https://github.com/containerd/containerd/releases/download/v${VERSION}/containerd-${VERSION}-linux-amd64.tar.gz tar xvf containerd-${VERSION}-linux-amd64.tar.gz -C /usr/local/ mkdir /etc/containerd/ \u0026\u0026 containerd config default \u003e /etc/containerd/config.toml wget -c -O /etc/systemd/system/containerd.service https://raw.githubusercontent.com/containerd/containerd/main/containerd.service systemctl start containerd \u0026\u0026 systemctl enable containerd  参阅容器运行时 以了解更多信息。\n","categories":"","description":"","excerpt":"本页介绍如何安装 kubeadm 工具箱。 有关在执行此安装过程后如何使用 kubeadm 创建集群的信息，请参见使用 kubeadm 创建 …","ref":"/zh/docs/pre-install/","tags":"","title":"安装准备"},{"body":"Clone single branch Since the repos branch is used as a software source for RPM and DEB, direct cloning is very large So try cloning only the single branch\ngit clone --single-branch -b master https://github.com/klts-io/kubernetes-lts ","categories":"","description":"","excerpt":"Clone single branch Since the repos branch is used as a software …","ref":"/docs/developer-guide/clone/","tags":"","title":"Clone"},{"body":"Install yq MacOS Red Hat-based distributions Debian-based distributions brew install jq python@3 # Install brew, See https://brew.sh/ pip3 install yq  yum install -y epel-release yum install -y jq python3 pip3 install yq  apt-get install -y jq python3 python3-pip pip3 install yq  ","categories":"","description":"","excerpt":"Install yq MacOS Red Hat-based distributions Debian-based …","ref":"/docs/developer-guide/dependent/","tags":"","title":"Dependent"},{"body":"KLTS provides a way to install software sources based on Deb and RPM. You can choose the installation method that suits your system\nBefore installation, ensure that related dependencies has been installed\nSet the KLTS software source Red Hat-based distributions Debian-based distributions cat \u003c\u003c \\EOF \u003e /etc/yum.repos.d/klts.repo [klts] name=klts baseurl=https://dl.klts.io/rpm/$basearch/ enabled=1 gpgcheck=0 EOF yum makecache  cat \u003c\u003c EOF \u003e /etc/apt/sources.list.d/klts.list deb [trusted=yes] https://dl.klts.io/deb stable main EOF apt-get update  Install Install Install the specified releases  Red Hat-based distributions Debian-based distributions yum install kubeadm kubelet kubectl  apt-get install kubeadm kubelet kubectl    Red Hat-based distributions Debian-based distributions # Search for supported releases yum search kubeadm --showduplicates | grep kubeadm- # Install VERSION=1.18.20-lts.0 yum install kubeadm-v${VERSION} kubelet-v${VERSION} kubectl-v${VERSION}  # Search for supported releases apt-cache show kubeadm | grep Version # Install VERSION=1.18.20-lts.0 apt-get install kubeadm=${VERSION} kubelet=${VERSION} kubectl=${VERSION}   Start Kubelet systemctl enable --now kubelet Pull the dependency image VERSION=1.18.20-lts.0 REPOS=ghcr.io/klts-io/kubernetes-lts kubeadm config images pull --image-repository ${REPOS} --kubernetes-version v${VERSION} All subsequent operations on Kubeadm need to include –image-repository, –kubernetes-version actively specifying the image\nInitialize the control plane node VERSION=1.18.20-lts.0 REPOS=ghcr.io/klts-io/kubernetes-lts kubeadm init --image-repository ${REPOS} --kubernetes-version v${VERSION} More Reference\n","categories":"","description":"","excerpt":"KLTS provides a way to install software sources based on Deb and RPM. …","ref":"/docs/install/","tags":"","title":"Install"},{"body":"安装 yq MacOS 基于 Red Hat 的发行版 基于 Debian 的发行版 brew install jq python@3 # 安装 brew, 请看 https://brew.sh/ pip3 install yq  yum install -y epel-release yum install -y jq python3 pip3 install yq  apt-get install -y jq python3 python3-pip pip3 install yq  ","categories":"","description":"","excerpt":"安装 yq MacOS 基于 Red Hat 的发行版 基于 Debian 的发行版 brew install jq python@3 #  …","ref":"/zh/docs/developer-guide/dependent/","tags":"","title":"依赖"},{"body":"克隆主分支 请尝试只克隆主分支, 由于 repos 仓库是作为 rpm 和 deb 的软件源的, 直接克隆全部的话会非常大\ngit clone --single-branch -b master https://github.com/klts-io/kubernetes-lts ","categories":"","description":"","excerpt":"克隆主分支 请尝试只克隆主分支, 由于 repos 仓库是作为 rpm 和 deb 的软件源的, 直接克隆全部的话会非常大\ngit …","ref":"/zh/docs/developer-guide/clone/","tags":"","title":"克隆"},{"body":"KLTS 提供了基于 deb 和 rpm 的软件源的安装方式. 您可以选择适合自己系统的安装安装方式\n安装前请确认已经完成了相关依赖的安装\n设置 KLTS 软件源 基于 Red Hat 的发行版 基于 Debian 的发行版 基于 Red Hat 的发行版, 国内加速 🚀 基于 Debian 的发行版, 国内加速 🚀 cat \u003c\u003c \\EOF \u003e /etc/yum.repos.d/klts.repo [klts] name=klts baseurl=https://dl.klts.io/rpm/$basearch/ enabled=1 gpgcheck=0 EOF yum makecache  cat \u003c\u003c EOF \u003e /etc/apt/sources.list.d/klts.list deb [trusted=yes] https://dl.klts.io/deb stable main EOF apt-get update   ⚠️ 以下加速均来自第三方, 安全和稳定性不做保障, 仅建议测试环境使用 ❗️❗️❗️  /etc/hosts hub.fastgit.org ghproxy.com raw.githubusercontents.com raw.staticdn.net curl https://raw.githubusercontent.com/wzshiming/github-hosts/master/hosts \u003e\u003e/etc/hosts cat \u003c\u003c \\EOF \u003e /etc/yum.repos.d/klts.repo [klts] name=klts baseurl=https://dl.klts.io/rpm/$basearch/ enabled=1 gpgcheck=0 EOF yum makecache  cat \u003c\u003c \\EOF \u003e /etc/yum.repos.d/klts.repo [klts] name=klts baseurl=https://hub.fastgit.org/klts-io/kubernetes-lts/raw/repos/rpm/$basearch/ enabled=1 gpgcheck=0 EOF yum makecache  cat \u003c\u003c \\EOF \u003e /etc/yum.repos.d/klts.repo [klts] name=klts baseurl=https://ghproxy.com/https://raw.githubusercontent.com/klts-io/kubernetes-lts/repos/rpm/$basearch/ enabled=1 gpgcheck=0 EOF yum makecache  cat \u003c\u003c \\EOF \u003e /etc/yum.repos.d/klts.repo [klts] name=klts baseurl=https://raw.githubusercontents.com/klts-io/kubernetes-lts/repos/rpm/$basearch/ enabled=1 gpgcheck=0 EOF yum makecache  cat \u003c\u003c \\EOF \u003e /etc/yum.repos.d/klts.repo [klts] name=klts baseurl=https://raw.staticdn.net/klts-io/kubernetes-lts/repos/rpm/$basearch/ enabled=1 gpgcheck=0 EOF yum makecache    ⚠️ 以下加速均来自第三方, 安全和稳定性不做保障, 仅建议测试环境使用 ❗️❗️❗️  /etc/hosts hub.fastgit.org ghproxy.com raw.githubusercontents.com raw.staticdn.net curl https://raw.githubusercontent.com/wzshiming/github-hosts/master/hosts \u003e\u003e/etc/hosts cat \u003c\u003c EOF \u003e /etc/apt/sources.list.d/klts.list deb [trusted=yes] https://dl.klts.io/deb stable main EOF apt-get update  cat \u003c\u003c EOF \u003e /etc/apt/sources.list.d/klts.list deb [trusted=yes] https://hub.fastgit.org/klts-io/kubernetes-lts/raw/repos/deb stable main EOF apt-get update  cat \u003c\u003c EOF \u003e /etc/apt/sources.list.d/klts.list deb [trusted=yes] https://ghproxy.com/https://raw.githubusercontent.com/klts-io/kubernetes-lts/repos/deb stable main EOF apt-get update  cat \u003c\u003c EOF \u003e /etc/apt/sources.list.d/klts.list deb [trusted=yes] https://raw.githubusercontents.com/klts-io/kubernetes-lts/repos/deb stable main EOF apt-get update  cat \u003c\u003c EOF \u003e /etc/apt/sources.list.d/klts.list deb [trusted=yes] https://raw.staticdn.net/klts-io/kubernetes-lts/repos/deb stable main EOF apt-get update   安装 安装 安装指定版本  基于 Red Hat 的发行版 基于 Debian 的发行版 yum install kubeadm kubelet kubectl  apt-get install kubeadm kubelet kubectl    基于 Red Hat 的发行版 基于 Debian 的发行版 # 搜索支持的版本 yum search kubeadm --showduplicates | grep kubeadm- # 安装 VERSION=1.18.20-lts.0 yum install kubeadm-v${VERSION} kubelet-v${VERSION} kubectl-v${VERSION}  # 搜索支持的版本 apt-cache show kubeadm | grep Version # 安装 VERSION=1.18.20-lts.0 apt-get install kubeadm=${VERSION} kubelet=${VERSION} kubectl=${VERSION}   启动 Kubelet systemctl enable --now kubelet 拉取依赖镜像 VERSION=1.18.20-lts.0 REPOS=ghcr.io/klts-io/kubernetes-lts kubeadm config images pull --image-repository ${REPOS} --kubernetes-version v${VERSION} 后续对 kubeadm 的操作都需要加上 –image-repository, –kubernetes-version 主动指定镜像\n初始化控制面节点 VERSION=1.18.20-lts.0 REPOS=ghcr.io/klts-io/kubernetes-lts kubeadm init --image-repository ${REPOS} --kubernetes-version v${VERSION} 更多操作参考\n","categories":"","description":"","excerpt":"KLTS 提供了基于 deb 和 rpm 的软件源的安装方式. 您可以选择适合自己系统的安装安装方式\n安装前请确认已经完成了相关依赖的安装\n …","ref":"/zh/docs/install/","tags":"","title":"安装步骤"},{"body":"TODO\n","categories":"","description":"","excerpt":"TODO\n","ref":"/docs/post-install/","tags":"","title":"Post Install"},{"body":"TODO\n","categories":"","description":"","excerpt":"TODO\n","ref":"/zh/docs/post-install/","tags":"","title":"安装之后"},{"body":"","categories":"","description":"","excerpt":"","ref":"/zh/docs/patches/","tags":"","title":"补丁"},{"body":"","categories":"","description":"","excerpt":"","ref":"/zh/docs/release-note/","tags":"","title":"版本日志"},{"body":"  #td-cover-block-0 { background-image: url(/about/featured-background_hu376e1fbab6ce6c455a2b3aa5c258c0d9_496231_960x540_fill_q75_catmullrom_bottom.jpg); } @media only screen and (min-width: 1200px) { #td-cover-block-0 { background-image: url(/about/featured-background_hu376e1fbab6ce6c455a2b3aa5c258c0d9_496231_1920x1080_fill_q75_catmullrom_bottom.jpg); } }  About KLTS KLTS (Kubernetes Long Term Support)        Kubernetes being an enterprise infrastructure, you should not use a version of Kubernetes that is no longer maintained. KLTS maintains the version that Kubernetes no longer maintains officially. You only need to upgrade to the KLTS patch version with minor fixes. To avoid bugs caused by upgrading your base to newer versions of Kubernetes, introducing features that are not currently available, Make Kubernetes more stable as your infrastructure.\n    The KLTS process is fully hosted on GitHub, and you can simply Fork the project and build your own version of Kubernetes. The build artifacts will all be stored on GitHub, the images will be stored in the GitHub Package, and the RPM and Deb packages will be stored in the repos branch of the same repository.      KLTS will maintain a release for at least 2 years after the official end of maintenance. Mainly to patch CVE vulnerabilities and more serious bugs.     ","categories":"","description":"","excerpt":"  #td-cover-block-0 { background-image: …","ref":"/about/","tags":"","title":"About KLTS"},{"body":"详细信息\n漏洞影响 kubectl cp 命令允许用户在容器和用户机器之间拷贝文件， 攻击者可能通过在镜像或运行容器中植入带有符号链接（symbolic links）头的恶意 tar 包，在 cp 命令执行解压过程中修改或监控符号链接头同名目录下的任意文件，造成破坏。\n官方修复的版本  1.14: 1.14.1 1.13: 1.13.6 1.12: 1.12.8 1.11: 1.11.10  KLTS 修复的版本  1.10: 1.10.13-lts.1 CVE-2019-1002101.1.10.patch  ","categories":"","description":"","excerpt":"详细信息\n漏洞影响 kubectl cp 命令允许用户在容器和用户机器之间拷贝文件， 攻击者可能通过在镜像或运行容器中植入带有符号链 …","ref":"/zh/docs/patches/cve-2019-1002101/","tags":"","title":"CVE-2019-1002101"},{"body":"TODO\n","categories":"","description":"","excerpt":"TODO\n","ref":"/zh/docs/patches/cve-2019-11245/","tags":"","title":"CVE-2019-11245"},{"body":"详细信息\n此漏洞可能允许攻击者利用 kubectl cp 命令，采用路径遍历(Path Traversal)的方式将容器 tar 包中的恶意文件写入所在主机上的任何路径，该过程仅受本地用户的系统权限限制。\n漏洞影响 该漏洞与不久前的 CVE-2019-1002101 漏洞影响相似，由于之前的相关漏洞修复。\nkubectl cp 命令用于用户容器和主机之间的文件拷贝，当从容器中拷贝文件时，Kubernetes 会首先在容器中执行 tar 命令创建相应的归档文件，然后发送给客户端，kubectl 会在用户主机上进行相应解压操作。\n如果容器 tar 包中包含恶意文件，当攻击者具有 kubectl cp 命令的执行权限时，可以利用路径遍历(Path Traversal)。\n官方修复的版本  1.14: 1.14.3 1.13: 1.13.7 1.12: 1.12.10  KLTS 修复的版本  1.11: 1.11.10-lts.1 CVE-2019-11246.1.10.patch 1.10: 1.10.13-lts.1 CVE-2019-11246.1.11.patch  ","categories":"","description":"","excerpt":"详细信息\n此漏洞可能允许攻击者利用 kubectl cp 命令，采用路径遍历(Path Traversal)的方式将容器 tar 包中的恶意 …","ref":"/zh/docs/patches/cve-2019-11246/","tags":"","title":"CVE-2019-11246"},{"body":"TODO\n","categories":"","description":"","excerpt":"TODO\n","ref":"/zh/docs/patches/cve-2019-11247/","tags":"","title":"CVE-2019-11247"},{"body":"TODO\n","categories":"","description":"","excerpt":"TODO\n","ref":"/zh/docs/patches/cve-2019-11248/","tags":"","title":"CVE-2019-11248"},{"body":"TODO\n","categories":"","description":"","excerpt":"TODO\n","ref":"/zh/docs/patches/cve-2019-11249/","tags":"","title":"CVE-2019-11249"},{"body":"TODO\n","categories":"","description":"","excerpt":"TODO\n","ref":"/zh/docs/patches/cve-2019-11251/","tags":"","title":"CVE-2019-11251"},{"body":"TODO\n","categories":"","description":"","excerpt":"TODO\n","ref":"/zh/docs/patches/cve-2020-8552/","tags":"","title":"CVE-2020-8552"},{"body":"详细信息\nkube-proxy 组件在 iptables 和 ipvs 模式下均需要设置内核参数 net.ipv4.conf.all.route_localnet=1， 从而允许本地回环访问。攻击者可能通过共享主机网络的容器，或在集群节点访问同一个LAN或二层网络下的相邻节点上绑定监听了本地 127.0.0.1 端口的 TCP/UDP 服务，从而获取接口信息。如果服务没有设置必要的安全认证，可能会造成信息泄露风险。\n漏洞影响 当攻击者拥有主机网络配置能力或运行在一个具备了 CAP_NET_RAW 能力的容器实例时，就可以获取在目标节点上监听了 127.0.0.1 的服务 socket 信息。如果在目标主机上存在 127.0.0.1 可以访问到且不需要任何认证鉴权的暴露服务，那么该服务信息就能被攻击者获取。\n漏洞评分  如果集群 API Server 开启了非认证端口（默认8080），那么攻击者可能获取到 API Server 接口相关信息，威胁等级为高危漏洞，评分为8.8分。 如果集群 API Server 默认关闭了非认证端口，威胁等级为中危漏洞，评分为5.4分。  可能的攻击者  同一交换机内的其他共享主机实例。 本机的运行容器。  防范措施 建议您采取以下安全防范措施：\n如果业务容器需使用主机网络模式且又监听在非安全端口上，可以通过在节点上手动添加 iptables 规则来缓解此漏洞。 执行以下命令，在集群中配置 iptables 规则，用于拒绝非本地对 127.0.0.1 的访问流量：\niptables -I INPUT --dst 127.0.0.0/8 ! --src 127.0.0.0/8 -m conntrack ! --ctstate RELATED,ESTABLISHED,DNAT -j DROP 如果集群不需要开启API Server 不安全端口，可以将 –insecure-port=0 添加到 kubernetes API 服务器命令行来禁用端口。\n如集群内运行有不受信的容器，可以禁止 Container 开启 CAP_NET_RAW 能力，可以在 pod spec 中关闭 Container 的 CAP_NET_RAW 能力。\nsecurityContext:capabilities:drop:- \"NET_RAW\"通过 PodSecurityPolicy 策略限制部署特权或共享主机网络容器，另外可以通过在策略中配置 requiredDropCapabilities 强制容器部署关闭 CAP_NET_RAW 能力。\n官方修复的版本  1.18: 1.18.4 1.17: 1.17.7 1.16: 1.16.11  KLTS 修复的版本  1.15: v1.15.12-lts.1 kubernetes/kubernetes#92040 1.14: v1.14.10-lts.1 kubernetes/kubernetes#92040 1.13: v1.13.12-lts.1 kubernetes/kubernetes#92040 1.12: v1.12.10-lts.1 CVE-2020-8558.1.12.patch 1.11: v1.11.10-lts.1 CVE-2020-8558.1.12.patch 1.10: v1.10.13-lts.1 TODO  ","categories":"","description":"","excerpt":"详细信息\nkube-proxy 组件在 iptables 和 ipvs …","ref":"/zh/docs/patches/cve-2020-8558/","tags":"","title":"CVE-2020-8558"},{"body":"详细信息\nkube-apiserver 组件的安全漏洞，攻击者可以通过截取某些发送至节点 kubelet 的升级请求，通过请求中原有的访问凭据转发请求至其他目标节点， 从而造成节点的权限提升漏洞。本文介绍该漏洞的影响范围、漏洞影响和防范措施。\n漏洞影响 由于 kube-apiserver 中在升级请求的代理后端中允许将请求传播回源客户端，攻击者可以通过截取某些发送至节点 kubelet 的升级请求，通过请求中原有的访问凭据转发请求至其他目标节点，从而造成被攻击节点的权限提升漏洞。\n漏洞评分 该漏洞为中危漏洞， CVSS 评分为6.4。 如果有多个集群共享使用了相同的 CA 和认证凭证，攻击者可以利用此漏洞攻击其他集群，这种情况下该漏洞为高危漏洞。\n防范措施 对于集群内跨节点的攻击，建议您采取以下安全防范措施：\n 及时吊销可能泄露的 kubeconfig 凭证，并且遵循权限最小化原则，收敛子账号不必要的 pods/exec、pods/attach、pods/portforward和 proxy 类型的资源模型 RBAC 权限。  官方修复的版本  1.18: 1.18.6 1.17: 1.17.9 1.16: 1.16.13  KLTS 修复的版本  1.15: 1.15.12-lts.1 kubernetes/kubernetes#92971 1.14: 1.14.10-lts.1 kubernetes/kubernetes#92971 1.13: 1.13.12-lts.1 TODO 1.12: 1.12.10-lts.1 TODO 1.11: 1.11.10-lts.1 TODO 1.10: 1.10.13-lts.1 TODO  ","categories":"","description":"","excerpt":"详细信息\nkube-apiserver 组件的安全漏洞，攻击者可以通过截取某些发送至节点 kubelet 的升级请求，通过请求中原有的访问凭 …","ref":"/zh/docs/patches/cve-2020-8559/","tags":"","title":"CVE-2020-8559"},{"body":"详细信息\n存在该漏洞的程序可能会因为处理了包含恶意 Protobuf 消息而崩溃。如果您使用的 Gogo Protobuf 编译器版本过低，可能存在该漏洞。本文介绍该漏洞的影响和影响范围，以及防范措施。\n漏洞影响 Kubernetes 系统组件由于自身有应对崩溃的恢复机制，当遇到恶意提交的 Protobuf 消息时不会中断服务，所以不在该漏洞的影响范围内。\n在应用系统中程序接收处理 Protobuf 消息时，如果组件没有应对崩溃的恢复机制，那么这类程序都在该漏洞影响范围内，且被恶意攻击时服务可能会中断。\nKubernetes 社区经过测试验证 API Server 不受该漏洞的影响，但为了避免您受到该安全漏洞隐患的影响，社区对相关 Protobuf 文件进行了升级，具体修复版本如下:\n防范措施 如果在您的应用系统代码中使用了自动生成的 Protobuf 消息，并且发现相关组件因为以下异常退出，则可能存在该漏洞。\npanic: runtime error: index out of range [-9223372036854775804] goroutine 1 [running]: v1.(*MessageName).Unmarshal(0xc00006f1e8, 0xc0000281a8, 0xa, 0x10, 0xc00006f1b8, 0x1) .../protofile.pb.go:250 +0xb86 如果您使用了 Protobuf 消息的相关组件，推荐将 Gogo Protobuf 编译器升级到漏洞修复版本（v1.3.2或更高的版本），再基于升级后的Protobuf编译器重新生成相关的Protobuf` 消息。\n官方修复的版本  1.21: 1.21.1 1.20: 1.20.7 1.19: 1.19.11 1.18: 1.18.19  KLTS 修复的版本  1.17: v1.17.17-lts.1 kubernetes/kubernetes#101327 1.16: v1.16.15-lts.1 kubernetes/kubernetes#101327 1.15: v1.15.12-lts.1 kubernetes/kubernetes#101327 1.14: v1.14.10-lts.1 kubernetes/kubernetes#101327 1.13: v1.13.12-lts.1 kubernetes/kubernetes#101327 1.12: v1.12.10-lts.1 kubernetes/kubernetes#101327 1.11: v1.11.10-lts.1 kubernetes/kubernetes#101327 1.10: v1.10.13-lts.1 kubernetes/kubernetes#101327  ","categories":"","description":"","excerpt":"详细信息\n存在该漏洞的程序可能会因为处理了包含恶意 Protobuf 消息而崩溃。如果您使用的 Gogo Protobuf 编译器版本过低， …","ref":"/zh/docs/patches/cve-2021-3121/","tags":"","title":"CVE-2021-3121"},{"body":"","categories":"","description":"","excerpt":"","ref":"/docs/developer-guide/","tags":"","title":"Developer Guide"},{"body":"","categories":"","description":"","excerpt":"","ref":"/docs/","tags":"","title":"Document"},{"body":"  #td-cover-block-0 { background-image: url(/featured-background_hu376e1fbab6ce6c455a2b3aa5c258c0d9_496231_960x540_fill_q75_catmullrom_top.jpg); } @media only screen and (min-width: 1200px) { #td-cover-block-0 { background-image: url(/featured-background_hu376e1fbab6ce6c455a2b3aa5c258c0d9_496231_1920x1080_fill_q75_catmullrom_top.jpg); } }  Welcome to KLTS.io Lean More   Source Code   Long term support of Kubernetes is available here\n         KLTS offers a production Kubernetes distribution, which is a fully open source Kubernetes distribution that provides a complete Kubernetes environment and dependencies\n      New chair metrics!  The Goldydocs UI now shows chair size metrics by default.\nPlease follow this space for updates!\n   Contributions welcome!  We do a Pull Request contributions workflow on GitHub. New users are always welcome!\nRead more …\n   Follow us on Twitter!  For announcement of latest features etc.\nRead more …\n     This is the second Section        Download **from AppStore**  Get the Goldydocs app!\n   Contributions welcome!  We do a Pull Request contributions workflow on GitHub. New users are always welcome!\nRead more …\n   Follow us on Twitter!  For announcement of latest features etc.\nRead more …\n     This is another Section     ","categories":"","description":"","excerpt":"  #td-cover-block-0 { background-image: …","ref":"/","tags":"","title":"KLTS.io"},{"body":"  #td-cover-block-0 { background-image: url(/zh/featured-background_hu376e1fbab6ce6c455a2b3aa5c258c0d9_496231_960x540_fill_q75_catmullrom_top.jpg); } @media only screen and (min-width: 1200px) { #td-cover-block-0 { background-image: url(/zh/featured-background_hu376e1fbab6ce6c455a2b3aa5c258c0d9_496231_1920x1080_fill_q75_catmullrom_top.jpg); } }  欢迎来到 KLTS.io 阅读文档   查看源码   稳定、长期维护的 Kubernetes 早期版本都在这里\n         KLTS 持续维护 Kubernetes 早期发行的版本，定期修复常见的 CVE 漏洞和 bug，可直接用于生产，完全开源，包含了完整的 Kubernetes 运行时环境及其依赖\n      DaoCloud 开源社区  提供镜像验证、交互设计、运维套件和文档开发等实用的开源工具！\n更多 …\n   欢迎加入 KLTS  我们在 GitHub 上开放了 Pull Request 贡献工作流。欢迎开发者加入！\n更多 …\n   了解 DaoCloud  企业级云计算领域的创新领导者\n更多 …\n       安装准备工作  安装 Kubernetes 的环境准备工作\n更多 …\n   安装  Kubernetes 的安装步骤\n更多 …\n   安装之后  安装 Kubernetes 之后需要执行的操作\n更多 …\n    ","categories":"","description":"","excerpt":"  #td-cover-block-0 { background-image: …","ref":"/zh/","tags":"","title":"KLTS.io"},{"body":"详细信息\nBug 影响 节点长期使用的时候提示剩余空间不足的错误，具体如下所示：\nmkdir: cannot create directory '/sys/fs/cgroup/memory/8': No space left on device 节点磁盘充足但是一直报和这个错误, 并且创建 Pod 总是失败，这是一个潜在的“定时炸弹”。\n影响范围 所有使用低版本内核的环境\nk8s 1.22 之前的版本都受到影响, 在 runc 1.0.0-rc94 (opencontainers/runc#2840) 修复(直接移除了)\n防范措施  升级系统内核 k8s 1.14 及以上  重新构建 Kubelet 带上 -tags=nokmem   k8s 1.14 以下  硬编码, 可以参考 nokmem.1.13.patch    KLTS 修复的版本  1.18: 1.18.20-lts.1 nokmem.1.18.patch 1.17: 1.17.17-lts.1 nokmem.1.18.patch 1.16: 1.16.15-lts.1 nokmem.1.18.patch 1.15: 1.15.12-lts.1 nokmem.1.18.patch 1.14: 1.14.10-lts.1 nokmem.1.18.patch 1.13: 1.13.12-lts.1 nokmem.1.13.patch 1.12: 1.12.10-lts.1 nokmem.1.13.patch 1.11: 1.11.10-lts.1 nokmem.1.13.patch 1.10: 1.10.13-lts.1 nokmem.1.13.patch  ","categories":"","description":"","excerpt":"详细信息\nBug 影响 节点长期使用的时候提示剩余空间不足的错误，具体如下所示：\nmkdir: cannot create …","ref":"/zh/docs/patches/nokmem/","tags":"","title":"nokmem"},{"body":"","categories":"","description":"","excerpt":"","ref":"/search/","tags":"","title":"Search Results"},{"body":"","categories":"","description":"","excerpt":"","ref":"/zh/search/","tags":"","title":"Search Results"},{"body":"","categories":"","description":"","excerpt":"","ref":"/zh/docs/release-note/v1.10.13/","tags":"","title":"v1.10.13"},{"body":"补丁  CVE-2019-11245 CVE-2019-1002101 CVE-2019-11246 CVE-2019-11247 TODO CVE-2019-11248 CVE-2019-11249 CVE-2019-11251 CVE-2020-8552 CVE-2020-8558 TODO CVE-2020-8559 TODO CVE-2021-3121 nokmem  ","categories":"","description":"","excerpt":"补丁  CVE-2019-11245 CVE-2019-1002101 CVE-2019-11246 CVE-2019-11247 TODO …","ref":"/zh/docs/release-note/v1.10.13/v1.10.13-lts.1/","tags":"","title":"v1.10.13-lts.1"},{"body":"","categories":"","description":"","excerpt":"","ref":"/zh/docs/release-note/v1.11.10/","tags":"","title":"v1.11.10"},{"body":"补丁  CVE-2019-11245 CVE-2019-11246 CVE-2019-11247 CVE-2019-11248 CVE-2019-11249 CVE-2019-11251 CVE-2020-8552 CVE-2020-8558 CVE-2020-8559 TODO CVE-2021-3121 nokmem  ","categories":"","description":"","excerpt":"补丁  CVE-2019-11245 CVE-2019-11246 CVE-2019-11247 CVE-2019-11248 …","ref":"/zh/docs/release-note/v1.11.10/v1.11.10-lts.1/","tags":"","title":"v1.11.10-lts.1"},{"body":"","categories":"","description":"","excerpt":"","ref":"/zh/docs/release-note/v1.12.10/","tags":"","title":"v1.12.10"},{"body":"补丁  CVE-2019-11245 CVE-2019-11247 CVE-2019-11249 CVE-2019-11251 CVE-2020-8552 CVE-2020-8558 CVE-2020-8559 TODO CVE-2021-3121 nokmem  ","categories":"","description":"","excerpt":"补丁  CVE-2019-11245 CVE-2019-11247 CVE-2019-11249 CVE-2019-11251 …","ref":"/zh/docs/release-note/v1.12.10/v1.12.10-lts.1/","tags":"","title":"v1.12.10-lts.1"},{"body":"","categories":"","description":"","excerpt":"","ref":"/zh/docs/release-note/v1.13.12/","tags":"","title":"v1.13.12"},{"body":"补丁  CVE-2020-8552 CVE-2020-8558 CVE-2020-8559 TODO CVE-2021-3121 nokmem  ","categories":"","description":"","excerpt":"补丁  CVE-2020-8552 CVE-2020-8558 CVE-2020-8559 TODO CVE-2021-3121 …","ref":"/zh/docs/release-note/v1.13.12/v1.13.12-lts.1/","tags":"","title":"v1.13.12-lts.1"},{"body":"","categories":"","description":"","excerpt":"","ref":"/zh/docs/release-note/v1.14.10/","tags":"","title":"v1.14.10"},{"body":"补丁  CVE-2020-8552 CVE-2020-8558 CVE-2020-8559 CVE-2021-3121 nokmem  ","categories":"","description":"","excerpt":"补丁  CVE-2020-8552 CVE-2020-8558 CVE-2020-8559 CVE-2021-3121 nokmem  ","ref":"/zh/docs/release-note/v1.14.10/v1.14.10-lts.1/","tags":"","title":"v1.14.10-lts.1"},{"body":"","categories":"","description":"","excerpt":"","ref":"/zh/docs/release-note/v1.15.12/","tags":"","title":"v1.15.12"},{"body":"补丁  CVE-2020-8558 CVE-2021-3121 nokmem  ","categories":"","description":"","excerpt":"补丁  CVE-2020-8558 CVE-2021-3121 nokmem  ","ref":"/zh/docs/release-note/v1.15.12/v1.15.12-lts.1/","tags":"","title":"v1.15.12-lts.1"},{"body":"","categories":"","description":"","excerpt":"","ref":"/zh/docs/release-note/v1.16.15/","tags":"","title":"v1.16.15"},{"body":"补丁  CVE-2021-3121 nokmem  ","categories":"","description":"","excerpt":"补丁  CVE-2021-3121 nokmem  ","ref":"/zh/docs/release-note/v1.16.15/v1.16.15-lts.1/","tags":"","title":"v1.16.15-lts.1"},{"body":"","categories":"","description":"","excerpt":"","ref":"/zh/docs/release-note/v1.17.17/","tags":"","title":"v1.17.17"},{"body":"补丁  CVE-2021-3121 nokmem  ","categories":"","description":"","excerpt":"补丁  CVE-2021-3121 nokmem  ","ref":"/zh/docs/release-note/v1.17.17/v1.17.17-lts.1/","tags":"","title":"v1.17.17-lts.1"},{"body":"","categories":"","description":"","excerpt":"","ref":"/zh/docs/release-note/v1.18.20/","tags":"","title":"v1.18.20"},{"body":"补丁  nokmem  ","categories":"","description":"","excerpt":"补丁  nokmem  ","ref":"/zh/docs/release-note/v1.18.20/v1.18.20-lts.1/","tags":"","title":"v1.18.20-lts.1"},{"body":"  #td-cover-block-0 { background-image: url(/zh/about/featured-background_hu376e1fbab6ce6c455a2b3aa5c258c0d9_496231_960x540_fill_q75_catmullrom_bottom.jpg); } @media only screen and (min-width: 1200px) { #td-cover-block-0 { background-image: url(/zh/about/featured-background_hu376e1fbab6ce6c455a2b3aa5c258c0d9_496231_1920x1080_fill_q75_catmullrom_bottom.jpg); } }  关于 KLTS KLTS (Kubernetes Long Term Support)        Kubernetes 是一个企业级容器集群管理系统，但目前社区仅维护最新的几个版本。 如果您使用的是较早的版本，该怎么办呢？不用担心，KLTS 帮助您维护社区不再维护的版本。 我们目前持续维护 1.10 到 1.18 近 10 个版本，您只需下载对应的版本，就能获得稳定运行的 Kubernetes 并享受持续维护的免费服务。\n    KLTS 所有流程完全托管在 GitHub 上，您可以直接 Fork 项目构建属于自己的 Kubernetes 版本。 所有镜像存放在 GitHub Package，而 rpm 和 deb 包存放在同仓库的 repos 分支。      Kubernetes 社区停止维护某个版本后，KLTS 将继续提供两年以上的维护，主要包括修补 CVE 漏洞和较为严重的 bug。      ","categories":"","description":"","excerpt":"  #td-cover-block-0 { background-image: …","ref":"/zh/about/","tags":"","title":"关于 KLTS"},{"body":"","categories":"","description":"","excerpt":"","ref":"/zh/docs/developer-guide/","tags":"","title":"开发指南"},{"body":"","categories":"","description":"","excerpt":"","ref":"/zh/docs/","tags":"","title":"文档"}]