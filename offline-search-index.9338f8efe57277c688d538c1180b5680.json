






















[{"body":"This page shows how to install the kubeadm toolbox. For information on how to create a cluster with kubeadm once you have performed this installation process, see the Using kubeadm to Create a Cluster page.\nBefore you begin  A compatible Linux host. The Kubernetes project provides generic instructions for Linux distributions based on Debian and Red Hat, and those distributions without a package manager. 2 GB or more of RAM per machine (any less will leave little room for your apps). 2 CPUs or more. Full network connectivity between all machines in the cluster (public or private network is fine). Unique hostname, MAC address, and product_uuid for every node. See here for more details. Certain ports are open on your machines. See here for more details. Swap disabled. You MUST disable swap in order for the kubelet to work properly.  Verify the MAC address and product_uuid are unique for every node  You can get the MAC address of the network interfaces using the command ip link or ifconfig -a The product_uuid can be checked by using the command sudo cat /sys/class/dmi/id/product_uuid  It is very likely that hardware devices will have unique addresses, although some virtual machines may have identical values. Kubernetes uses these values to uniquely identify the nodes in the cluster. If these values are not unique to each node, the installation process may fail.\nCheck network adapters If you have more than one network adapter, and your Kubernetes components are not reachable on the default route, we recommend you add IP route(s) so Kubernetes cluster addresses go via the appropriate adapter.\nLetting iptables see bridged traffic Make sure that the br_netfilter module is loaded. This can be done by running lsmod | grep br_netfilter. To load it explicitly call sudo modprobe br_netfilter.\nAs a requirement for your Linux Node’s iptables to correctly see bridged traffic, you should ensure net.bridge.bridge-nf-call-iptables is set to 1 in your sysctl config, e.g.\ncat \u003c\u003cEOF | sudo tee /etc/modules-load.d/k8s.conf br_netfilter EOF cat \u003c\u003cEOF | sudo tee /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 EOF sudo sysctl --system For more details please see the Network Plugin Requirements page.\nCheck required ports Control-plane node(s)    Protocol Direction Port Range Purpose Used By     TCP Inbound 6443* Kubernetes API server All   TCP Inbound 2379-2380 etcd server client API kube-apiserver, etcd   TCP Inbound 10250 kubelet API Self, Control plane   TCP Inbound 10251 kube-scheduler Self   TCP Inbound 10252 kube-controller-manager Self    Worker node(s)    Protocol Direction Port Range Purpose Used By     TCP Inbound 10250 kubelet API Self, Control plane   TCP Inbound 30000-32767 NodePort Services† All    † Default port range for NodePort Services.\nAny port numbers marked with * are overridable, so you will need to ensure any custom ports you provide are also open.\nAlthough etcd ports are included in control-plane nodes, you can also host your own etcd cluster externally or on custom ports.\nThe pod network plugin you use (see below) may also require certain ports to be open. Since this differs with each pod network plugin, please see the documentation for the plugins about what port(s) those need.\nSetting node name hostnamectl set-hostname your-new-host-name echo \"127.0.0.1 $(hostname)\" \u003e\u003e /etc/hosts echo \"::1 $(hostname)\" \u003e\u003e /etc/hosts Disable Swap swapoff -a If you want to disable swap permanently, edit the /etc/fstab file to comment out the swap mount\nDisable Selinux setenforce 0 If you want to disable selinux permanently, edit /etc/sysconfig/selinux and replace SELINUX=enforcing with SELINUX=disabled\nInstall Runtime To run containers in Pods, Kubernetes uses a Container Runtime Interface (Container Runtime)\nLinux Node 其它操作系统 By default, Kubernetes uses the Container Runtime Interface (CRI) to interface with your chosen container runtime.\nIf you don’t specify a runtime, kubeadm automatically tries to detect an installed container runtime by scanning through a list of well known Unix domain sockets. The following table lists container runtimes and their associated socket paths:\n   Runtime Path to Unix domain socket     Docker /var/run/dockershim.sock   Containerd /run/containerd/containerd.sock   CRI-O /var/run/crio/crio.sock     If both Docker and containerd are detected, Docker takes precedence. This is needed because Docker 18.09 ships with containerd and both are detectable even if you only installed Docker. If any other two or more runtimes are detected, kubeadm exits with an error. The kubelet integrates with Docker through the built-in dockershim CRI implementation.\n By default, kubeadm uses Docker as the container runtime. The kubelet integrates with Docker through the built-in dockershim CRI implementation.\n Docker Containerd  Red Hat-based distributions Debian-based distributions yum install docker  apt-get install docker.io   VERSION=1.5.4 wget -c https://github.com/containerd/containerd/releases/download/v${VERSION}/containerd-${VERSION}-linux-amd64.tar.gz tar xvf containerd-${VERSION}-linux-amd64.tar.gz -C /usr/local/ mkdir /etc/containerd/ \u0026\u0026 containerd config default \u003e /etc/containerd/config.toml wget -c -O /etc/systemd/system/containerd.service https://raw.githubusercontent.com/containerd/containerd/main/containerd.service systemctl start containerd \u0026\u0026 systemctl enable containerd  See container runtimes for more information.\n","categories":"","description":"","excerpt":"This page shows how to install the kubeadm toolbox. For information on …","ref":"/docs/pre-install/","tags":"","title":"Pre Install"},{"body":"本页面显示如何安装 kubeadm 工具箱。 有关在执行此安装过程后如何使用 kubeadm 创建集群的信息，请参见 使用 kubeadm 创建集群 页面。\n准备开始  一台兼容的 Linux 主机。Kubernetes 项目为基于 Debian 和 Red Hat 的 Linux 发行版以及一些不提供包管理器的发行版提供通用的指令 每台机器 2 GB 或更多的 RAM （如果少于这个数字将会影响你应用的运行内存) 2 CPU 核或更多 集群中的所有机器的网络彼此均能相互连接(公网和内网都可以) 节点之中不可以有重复的主机名、MAC 地址或 product_uuid。请参见这里了解更多详细信息。 开启机器上的某些端口。请参见这里 了解更多详细信息。 禁用交换分区。为了保证 kubelet 正常工作，你 必须 禁用交换分区。  确保每个节点上 MAC 地址和 product_uuid 的唯一性   你可以使用命令 ip link 或 ifconfig -a 来获取网络接口的 MAC 地址 可以使用 sudo cat /sys/class/dmi/id/product_uuid 命令对 product_uuid 校验  一般来讲，硬件设备会拥有唯一的地址，但是有些虚拟机的地址可能会重复。 Kubernetes 使用这些值来唯一确定集群中的节点。 如果这些值在每个节点上不唯一，可能会导致安装 失败。\n检查网络适配器 如果你有一个以上的网络适配器，同时你的 Kubernetes 组件通过默认路由不可达，我们建议你预先添加 IP 路由规则，这样 Kubernetes 集群就可以通过对应的适配器完成连接。\n允许 iptables 检查桥接流量 确保 br_netfilter 模块被加载。这一操作可以通过运行 lsmod | grep br_netfilter 来完成。若要显式加载该模块，可执行 sudo modprobe br_netfilter。\n为了让你的 Linux 节点上的 iptables 能够正确地查看桥接流量，你需要确保在你的 sysctl 配置中将 net.bridge.bridge-nf-call-iptables 设置为 1。例如：\ncat \u003c\u003cEOF | sudo tee /etc/modules-load.d/k8s.conf br_netfilter EOF cat \u003c\u003cEOF | sudo tee /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 EOF sudo sysctl --system 更多的相关细节可查看网络插件需求页面。\n检查所需端口 控制平面节点    协议 方向 端口范围 作用 使用者     TCP 入站 6443 Kubernetes API 服务器 所有组件   TCP 入站 2379-2380 etcd 服务器客户端 API kube-apiserver, etcd   TCP 入站 10250 Kubelet API kubelet 自身、控制平面组件   TCP 入站 10251 kube-scheduler kube-scheduler 自身   TCP 入站 10252 kube-controller-manager kube-controller-manager 自身    工作节点    协议 方向 端口范围 作用 使用者     TCP 入站 10250 Kubelet API kubelet 自身、控制平面组件   TCP 入站 30000-32767 NodePort 服务† 所有组件    NodePort 服务 的默认端口范围。\n使用 * 标记的任意端口号都可以被覆盖，所以你需要保证所定制的端口是开放的。\n虽然控制平面节点已经包含了 etcd 的端口，你也可以使用自定义的外部 etcd 集群，或是指定自定义端口。\n你使用的 Pod 网络插件 (见下) 也可能需要某些特定端口开启。由于各个 Pod 网络插件都有所不同， 请参阅他们各自文档中对端口的要求。\n设置节点名字 hostnamectl set-hostname your-new-host-name echo \"127.0.0.1 $(hostname)\" \u003e\u003e /etc/hosts echo \"::1 $(hostname)\" \u003e\u003e /etc/hosts 关闭 Swap swapoff -a 如需要永久关闭请编辑 /etc/fstab 文件注释掉 swap 的挂载\n关闭 Selinux setenforce 0 如需要永久关闭请编辑 /etc/sysconfig/selinux 把 SELINUX=enforcing 替换为 SELINUX=disabled\n安装 runtime 为了在 Pod 中运行容器，Kubernetes 使用 容器运行时（Container Runtime）\nLinux 节点 其它操作系统 默认情况下，Kubernetes 使用 容器运行时接口（Container Runtime Interface，CRI） 来与你所选择的容器运行时交互。\n如果你不指定运行时，则 kubeadm 会自动尝试检测到系统上已经安装的运行时， 方法是扫描一组众所周知的 Unix 域套接字。 下面的表格列举了一些容器运行时及其对应的套接字路径：\n   运行时 域套接字     Docker /var/run/dockershim.sock   Containerd /run/containerd/containerd.sock   CRI-O /var/run/crio/crio.sock     如果同时检测到 Docker 和 containerd，则优先选择 Docker。 这是必然的，因为 Docker 18.09 附带了 containerd 并且两者都是可以检测到的， 即使你仅安装了 Docker。 如果检测到其他两个或多个运行时，kubeadm 输出错误信息并退出。 kubelet 通过内置的 dockershim CRI 实现与 Docker 集成。\n 默认情况下， kubeadm 使用 docker 作为容器运行时。 kubelet 通过内置的 dockershim CRI 实现与 Docker 集成。\n Docker Containerd  基于 Red Hat 的发行版 基于 Debian 的发行版 yum install docker  apt-get install docker.io   VERSION=1.5.4 wget -c https://github.com/containerd/containerd/releases/download/v${VERSION}/containerd-${VERSION}-linux-amd64.tar.gz tar xvf containerd-${VERSION}-linux-amd64.tar.gz -C /usr/local/ mkdir /etc/containerd/ \u0026\u0026 containerd config default \u003e /etc/containerd/config.toml wget -c -O /etc/systemd/system/containerd.service https://raw.githubusercontent.com/containerd/containerd/main/containerd.service systemctl start containerd \u0026\u0026 systemctl enable containerd  参阅容器运行时 以了解更多信息。\n","categories":"","description":"","excerpt":"本页面显示如何安装 kubeadm 工具箱。 有关在执行此安装过程后如何使用 kubeadm 创建集群的信息，请参见 使用 kubeadm  …","ref":"/zh/docs/pre-install/","tags":"","title":"安装预备"},{"body":"Clone single branch Since the repos branch is used as a software source for RPM and DEB, direct cloning is very large So try cloning only the single branch\ngit clone --single-branch -b master https://github.com/klts-io/kubepatch ","categories":"","description":"","excerpt":"Clone single branch Since the repos branch is used as a software …","ref":"/docs/developer-guide/clone/","tags":"","title":"Clone"},{"body":"Install yq MacOS Red Hat-based distributions Debian-based distributions brew install jq python@3 # Install brew, See https://brew.sh/ pip3 install yq  yum install -y epel-release yum install -y jq python3 pip3 install yq  apt-get install -y jq python3 python3-pip pip3 install yq  ","categories":"","description":"","excerpt":"Install yq MacOS Red Hat-based distributions Debian-based …","ref":"/docs/developer-guide/dependent/","tags":"","title":"Dependent"},{"body":"KLTS provides a way to install software sources based on Deb and RPM. You can choose the installation method that suits your system\nBefore installation, ensure that related dependencies has been installed\nSet the KLTS software source Red Hat-based distributions Debian-based distributions cat \u003c\u003c \\EOF \u003e /etc/yum.repos.d/klts.repo [klts] name=klts baseurl=https://raw.githubusercontent.com/klts-io/kubepatch/repos/rpm/$basearch/ enabled=1 gpgcheck=0 EOF yum makecache  cat \u003c\u003c EOF \u003e /etc/apt/sources.list.d/klts.list deb [trusted=yes] https://raw.githubusercontent.com/klts-io/kubepatch/repos/deb stable main EOF apt-get update  Install Install Install the specified releases  Red Hat-based distributions Debian-based distributions yum install kubeadm kubelet kubectl  apt-get install kubeadm kubelet kubectl    Red Hat-based distributions Debian-based distributions # Search for supported releases yum search kubeadm --showduplicates | grep kubeadm- # Install VERSION=1.18.20-lts.0 yum install kubeadm-v${VERSION} kubelet-v${VERSION} kubectl-v${VERSION}  # Search for supported releases apt-cache show kubeadm | grep Version # Install VERSION=1.18.20-lts.0 apt-get install kubeadm=${VERSION} kubelet=${VERSION} kubectl=${VERSION}   Start Kubelet systemctl enable --now kubelet Pull the dependency image VERSION=1.18.20-lts.0 REPOS=ghcr.io/klts-io/kubepatch kubeadm config images pull --image-repository ${REPOS} --kubernetes-version v${VERSION} All subsequent operations on Kubeadm need to include –image-repository, –kubernetes-version actively specifying the image\nInitialize the control plane node VERSION=1.18.20-lts.0 REPOS=ghcr.io/klts-io/kubepatch kubeadm init --image-repository ${REPOS} --kubernetes-version v${VERSION} More Reference\n","categories":"","description":"","excerpt":"KLTS provides a way to install software sources based on Deb and RPM. …","ref":"/docs/install/","tags":"","title":"Install"},{"body":"安装 yq MacOS 基于 Red Hat 的发行版 基于 Debian 的发行版 brew install jq python@3 # 安装 brew, 请看 https://brew.sh/ pip3 install yq  yum install -y epel-release yum install -y jq python3 pip3 install yq  apt-get install -y jq python3 python3-pip pip3 install yq  ","categories":"","description":"","excerpt":"安装 yq MacOS 基于 Red Hat 的发行版 基于 Debian 的发行版 brew install jq python@3 #  …","ref":"/zh/docs/developer-guide/dependent/","tags":"","title":"依赖"},{"body":"克隆主分支 请尝试只克隆主分支, 由于 repos 仓库是作为 rpm 和 deb 的软件源的, 直接克隆全部的话会非常大\ngit clone --single-branch -b master https://github.com/klts-io/kubepatch ","categories":"","description":"","excerpt":"克隆主分支 请尝试只克隆主分支, 由于 repos 仓库是作为 rpm 和 deb 的软件源的, 直接克隆全部的话会非常大\ngit …","ref":"/zh/docs/developer-guide/clone/","tags":"","title":"克隆"},{"body":"KLTS 提供了基于 deb 和 rpm 的软件源的安装方式. 您可以选择适合自己系统的安装安装方式\n安装前请确认已经完成了相关依赖的安装\n设置 KLTS 软件源 基于 Red Hat 的发行版 基于 Debian 的发行版 基于 Red Hat 的发行版, 国内加速 🚀 基于 Debian 的发行版, 国内加速 🚀 cat \u003c\u003c \\EOF \u003e /etc/yum.repos.d/klts.repo [klts] name=klts baseurl=https://raw.githubusercontent.com/klts-io/kubepatch/repos/rpm/$basearch/ enabled=1 gpgcheck=0 EOF yum makecache  cat \u003c\u003c EOF \u003e /etc/apt/sources.list.d/klts.list deb [trusted=yes] https://raw.githubusercontent.com/klts-io/kubepatch/repos/deb stable main EOF apt-get update   ⚠️ 以下加速均来自第三方, 安全和稳定性不做保障, 仅建议测试环境使用 ❗️❗️❗️  /etc/hosts hub.fastgit.org ghproxy.com raw.githubusercontents.com raw.staticdn.net curl https://raw.githubusercontent.com/wzshiming/github-hosts/master/hosts \u003e\u003e/etc/hosts cat \u003c\u003c \\EOF \u003e /etc/yum.repos.d/klts.repo [klts] name=klts baseurl=https://raw.githubusercontent.com/klts-io/kubepatch/repos/rpm/$basearch/ enabled=1 gpgcheck=0 EOF yum makecache  cat \u003c\u003c \\EOF \u003e /etc/yum.repos.d/klts.repo [klts] name=klts baseurl=https://hub.fastgit.org/klts-io/kubepatch/raw/repos/rpm/$basearch/ enabled=1 gpgcheck=0 EOF yum makecache  cat \u003c\u003c \\EOF \u003e /etc/yum.repos.d/klts.repo [klts] name=klts baseurl=https://ghproxy.com/https://raw.githubusercontent.com/klts-io/kubepatch/repos/rpm/$basearch/ enabled=1 gpgcheck=0 EOF yum makecache  cat \u003c\u003c \\EOF \u003e /etc/yum.repos.d/klts.repo [klts] name=klts baseurl=https://raw.githubusercontents.com/klts-io/kubepatch/repos/rpm/$basearch/ enabled=1 gpgcheck=0 EOF yum makecache  cat \u003c\u003c \\EOF \u003e /etc/yum.repos.d/klts.repo [klts] name=klts baseurl=https://raw.staticdn.net/klts-io/kubepatch/repos/rpm/$basearch/ enabled=1 gpgcheck=0 EOF yum makecache    ⚠️ 以下加速均来自第三方, 安全和稳定性不做保障, 仅建议测试环境使用 ❗️❗️❗️  /etc/hosts hub.fastgit.org ghproxy.com raw.githubusercontents.com raw.staticdn.net curl https://raw.githubusercontent.com/wzshiming/github-hosts/master/hosts \u003e\u003e/etc/hosts cat \u003c\u003c EOF \u003e /etc/apt/sources.list.d/klts.list deb [trusted=yes] https://raw.githubusercontent.com/klts-io/kubepatch/repos/deb stable main EOF apt-get update  cat \u003c\u003c EOF \u003e /etc/apt/sources.list.d/klts.list deb [trusted=yes] https://hub.fastgit.org/klts-io/kubepatch/raw/repos/deb stable main EOF apt-get update  cat \u003c\u003c EOF \u003e /etc/apt/sources.list.d/klts.list deb [trusted=yes] https://ghproxy.com/https://raw.githubusercontent.com/klts-io/kubepatch/repos/deb stable main EOF apt-get update  cat \u003c\u003c EOF \u003e /etc/apt/sources.list.d/klts.list deb [trusted=yes] https://raw.githubusercontents.com/klts-io/kubepatch/repos/deb stable main EOF apt-get update  cat \u003c\u003c EOF \u003e /etc/apt/sources.list.d/klts.list deb [trusted=yes] https://raw.staticdn.net/klts-io/kubepatch/repos/deb stable main EOF apt-get update   安装 安装 安装指定版本  基于 Red Hat 的发行版 基于 Debian 的发行版 yum install kubeadm kubelet kubectl  apt-get install kubeadm kubelet kubectl    基于 Red Hat 的发行版 基于 Debian 的发行版 # 搜索支持的版本 yum search kubeadm --showduplicates | grep kubeadm- # 安装 VERSION=1.18.20-lts.0 yum install kubeadm-v${VERSION} kubelet-v${VERSION} kubectl-v${VERSION}  # 搜索支持的版本 apt-cache show kubeadm | grep Version # 安装 VERSION=1.18.20-lts.0 apt-get install kubeadm=${VERSION} kubelet=${VERSION} kubectl=${VERSION}   启动 Kubelet systemctl enable --now kubelet 拉取依赖镜像 VERSION=1.18.20-lts.0 REPOS=ghcr.io/klts-io/kubepatch kubeadm config images pull --image-repository ${REPOS} --kubernetes-version v${VERSION} 后续对 kubeadm 的操作都需要加上 –image-repository, –kubernetes-version 主动指定镜像\n初始化控制面节点 VERSION=1.18.20-lts.0 REPOS=ghcr.io/klts-io/kubepatch kubeadm init --image-repository ${REPOS} --kubernetes-version v${VERSION} 更多操作参考\n","categories":"","description":"","excerpt":"KLTS 提供了基于 deb 和 rpm 的软件源的安装方式. 您可以选择适合自己系统的安装安装方式\n安装前请确认已经完成了相关依赖的安装\n …","ref":"/zh/docs/install/","tags":"","title":"安装"},{"body":"TODO\n","categories":"","description":"","excerpt":"TODO\n","ref":"/docs/post-install/","tags":"","title":"Post Install"},{"body":"TODO\n","categories":"","description":"","excerpt":"TODO\n","ref":"/zh/docs/post-install/","tags":"","title":"安装后续"},{"body":"  #td-cover-block-0 { background-image: url(/about/featured-background_hu376e1fbab6ce6c455a2b3aa5c258c0d9_496231_960x540_fill_q75_catmullrom_bottom.jpg); } @media only screen and (min-width: 1200px) { #td-cover-block-0 { background-image: url(/about/featured-background_hu376e1fbab6ce6c455a2b3aa5c258c0d9_496231_1920x1080_fill_q75_catmullrom_bottom.jpg); } }  About KLTS KLTS (Kubernetes Long Term Support)        Kubernetes being an enterprise infrastructure, you should not use a version of Kubernetes that is no longer maintained. KLTS maintains the version that Kubernetes no longer maintains officially. You only need to upgrade to the KLTS patch version with minor fixes. To avoid bugs caused by upgrading your base to newer versions of Kubernetes, introducing features that are not currently available, Make Kubernetes more stable as your infrastructure.\n    The KLTS process is fully hosted on GitHub, and you can simply Fork the project and build your own version of Kubernetes. The build artifacts will all be stored on GitHub, the images will be stored in the GitHub Package, and the RPM and Deb packages will be stored in the repos branch of the same repository.      KLTS will maintain a release for at least 2 years after the official end of maintenance. Mainly to patch CVE vulnerabilities and more serious bugs.     ","categories":"","description":"","excerpt":"  #td-cover-block-0 { background-image: …","ref":"/about/","tags":"","title":"About KLTS"},{"body":"详细信息\nKubernetes 社区披露了编号为 CVE-2021-3121 的安全漏洞，存在该漏洞的程序可能会因为处理了包含恶意 Protobuf 消息而崩溃。如果您使用的 Gogo Protobuf 编译器版本过低，可能存在该漏洞。本文介绍该漏洞的影响和影响范围，以及防范措施。\n漏洞影响 Kubernetes 系统组件由于自身有应对崩溃的恢复机制，当遇到恶意提交的 Protobuf 消息时不会中断服务，所以不在该漏洞的影响范围内。\n在应用系统中程序接收处理 Protobuf 消息时，如果组件没有应对崩溃的恢复机制，那么这类程序都在该漏洞影响范围内，且被恶意攻击时服务可能会中断。\n影响范围 Kubernetes 社区经过测试验证 API Server 不受该漏洞的影响，但为了避免您受到该安全漏洞隐患的影响，社区对相关 Protobuf 文件进行了升级，具体修复版本如下:\n 1.21: 1.21.0、1.21.1 1.20: 1.20.6、1.20.7 1.19: 1.19.10、1.19.11 1.18: 1.18.18、1.18.19  防范措施 如果在您的应用系统代码中使用了自动生成的Protobuf消息，并且发现相关组件因为以下异常退出，则可能存在该漏洞。\npanic: runtime error: index out of range [-9223372036854775804] goroutine 1 [running]: v1.(*MessageName).Unmarshal(0xc00006f1e8, 0xc0000281a8, 0xa, 0x10, 0xc00006f1b8, 0x1) .../protofile.pb.go:250 +0xb86 如果您使用了 Protobuf 消息的相关组件，推荐将 Gogo Protobuf 编译器升级到漏洞修复版本（v1.3.2或更高的版本），再基于升级后的Protobuf 编译器重新生成相关的 Protobuf 消息。\nKLTS 修复的版本  (TODO 替换 lts.x 为正式版本号)\n  1.17: v1.17.17-lts.x kubernetes/kubernetes#101327 1.16: v1.16.15-lts.x kubernetes/kubernetes#101327 1.15: v1.15.12-lts.x kubernetes/kubernetes#101327 1.14: v1.14.10-lts.x kubernetes/kubernetes#101327 1.13: v1.13.12-lts.x kubernetes/kubernetes#101327 1.12: v1.12.10-lts.x kubernetes/kubernetes#101327 1.11: v1.11.10-lts.x kubernetes/kubernetes#101327 1.10: v1.10.13-lts.x kubernetes/kubernetes#101327  ","categories":"","description":"","excerpt":"详细信息\nKubernetes 社区披露了编号为 CVE-2021-3121 的安全漏洞， …","ref":"/zh/docs/patches/cve-2021-3121/","tags":"","title":"CVE-2021-3121"},{"body":"","categories":"","description":"","excerpt":"","ref":"/docs/developer-guide/","tags":"","title":"Developer Guide"},{"body":"","categories":"","description":"","excerpt":"","ref":"/docs/","tags":"","title":"Document"},{"body":"  #td-cover-block-0 { background-image: url(/featured-background_hu376e1fbab6ce6c455a2b3aa5c258c0d9_496231_960x540_fill_q75_catmullrom_top.jpg); } @media only screen and (min-width: 1200px) { #td-cover-block-0 { background-image: url(/featured-background_hu376e1fbab6ce6c455a2b3aa5c258c0d9_496231_1920x1080_fill_q75_catmullrom_top.jpg); } }  Welcome to KLTS.io Lean More   Source Code   Long term support of Kubernetes is available here\n         KLTS offers a production Kubernetes distribution, which is a fully open source Kubernetes distribution that provides a complete Kubernetes environment and dependencies\n      New chair metrics!  The Goldydocs UI now shows chair size metrics by default.\nPlease follow this space for updates!\n   Contributions welcome!  We do a Pull Request contributions workflow on GitHub. New users are always welcome!\nRead more …\n   Follow us on Twitter!  For announcement of latest features etc.\nRead more …\n     This is the second Section        Download **from AppStore**  Get the Goldydocs app!\n   Contributions welcome!  We do a Pull Request contributions workflow on GitHub. New users are always welcome!\nRead more …\n   Follow us on Twitter!  For announcement of latest features etc.\nRead more …\n     This is another Section     ","categories":"","description":"","excerpt":"  #td-cover-block-0 { background-image: …","ref":"/","tags":"","title":"KLTS.io"},{"body":"  #td-cover-block-0 { background-image: url(/zh/featured-background_hu376e1fbab6ce6c455a2b3aa5c258c0d9_496231_960x540_fill_q75_catmullrom_top.jpg); } @media only screen and (min-width: 1200px) { #td-cover-block-0 { background-image: url(/zh/featured-background_hu376e1fbab6ce6c455a2b3aa5c258c0d9_496231_1920x1080_fill_q75_catmullrom_top.jpg); } }  欢迎来到 KLTS.io 阅读文档   查看源码   稳定长期维护的旧版本 Kubernetes，就在这里\n         KLTS 提供的旧版本 Kubernetes 是持续维护的正式发行版，可直接用于生产，完全开源，包含了完整的 Kubernetes 运行时环境及其依赖\n      DaoCloud Enterprise 云原生应用云平台  内核从 Kubernetes 1.10 到最新版本，其中 1.10 版本已维护了 3 年以上！\n更多 …\n   欢迎任何贡献者！  我们在 GitHub 上开放了 Pull Request 贡献工作流。欢迎开发者加入！\n更多 …\n   了解我们！  企业级云计算领域的创新领导者\n更多 …\n       Download **from AppStore**  Get the Goldydocs app!\n   Contributions welcome!  We do a Pull Request contributions workflow on GitHub. New users are always welcome!\n更多 …\n   Follow us on Twitter!  For announcement of latest features etc.\n更多 …\n    ","categories":"","description":"","excerpt":"  #td-cover-block-0 { background-image: …","ref":"/zh/","tags":"","title":"KLTS.io"},{"body":"详细信息\nBug 影响 节点长期使用的时候提示剩余空间不足的错误，具体如下所示：\nmkdir: cannot create directory '/sys/fs/cgroup/memory/8': No space left on device 节点磁盘充足但是一直报和这个错误, 并且创建 Pod 总是失败，这是一个潜在的“定时炸弹”。\n影响范围 所有使用低版本内核的环境\nk8s 1.22 之前的版本都受到影响, 在 runc 1.0.0-rc94 (opencontainers/runc#2840) 修复(直接移除了)\n防范错误  升级系统内核 k8s 1.14 及以上  重新构建 Kubelet 带上 -tags=nokmem   k8s 1.14 以下  硬编码, 可以参考 nokmem.1.13.patch    KLTS 修复的版本  (TODO 替换 lts.x 为正式版本号)\n  1.18: v1.18.20-lts.x nokmem.1.18.patch 1.17: v1.17.17-lts.x nokmem.1.18.patch 1.16: v1.16.15-lts.x nokmem.1.18.patch 1.15: v1.15.12-lts.x nokmem.1.18.patch 1.14: v1.14.10-lts.x nokmem.1.18.patch 1.13: v1.13.12-lts.x nokmem.1.13.patch 1.12: v1.12.10-lts.x nokmem.1.13.patch 1.11: v1.11.10-lts.x nokmem.1.13.patch 1.10: v1.10.13-lts.x nokmem.1.13.patch  ","categories":"","description":"","excerpt":"详细信息\nBug 影响 节点长期使用的时候提示剩余空间不足的错误，具体如下所示：\nmkdir: cannot create …","ref":"/zh/docs/patches/nokmem/","tags":"","title":"nokmem"},{"body":"","categories":"","description":"","excerpt":"","ref":"/search/","tags":"","title":"Search Results"},{"body":"","categories":"","description":"","excerpt":"","ref":"/zh/search/","tags":"","title":"Search Results"},{"body":"  #td-cover-block-0 { background-image: url(/zh/about/featured-background_hu376e1fbab6ce6c455a2b3aa5c258c0d9_496231_960x540_fill_q75_catmullrom_bottom.jpg); } @media only screen and (min-width: 1200px) { #td-cover-block-0 { background-image: url(/zh/about/featured-background_hu376e1fbab6ce6c455a2b3aa5c258c0d9_496231_1920x1080_fill_q75_catmullrom_bottom.jpg); } }  关于 KLTS KLTS (Kubernetes Long Term Support)        Kubernetes 是一个企业级容器集群管理系统，但目前官方仅维护最新的几个版本。 如果您使用的是 1.18 之前的版本，该怎么办呢？不用担心，KLTS 帮助您维护官方不再维护的版本。 我们目前持续维护 1.10 到 1.18 近 10 个版本，您只需下载对应的版本，就能获得稳定运行的 Kubernetes 并享受持续维护的免费服务。\n    KLTS 所有流程完全托管在 GitHub 上，您可以直接 Fork 项目构建属于自己的 Kubernetes 版本。 所有镜像存放在 GitHub Package，而 rpm 和 deb 包存放在同仓库的 repos 分支。      Kubernetes 官方结束维护某个版本后，KLTS 将继续提供两年以上的维护，主要包括修补 CVE 漏洞和较为严重的 bug。      ","categories":"","description":"","excerpt":"  #td-cover-block-0 { background-image: …","ref":"/zh/about/","tags":"","title":"关于 KLTS"},{"body":"","categories":"","description":"","excerpt":"","ref":"/zh/docs/developer-guide/","tags":"","title":"开发指南"},{"body":"","categories":"","description":"","excerpt":"","ref":"/zh/docs/","tags":"","title":"文档"},{"body":"","categories":"","description":"","excerpt":"","ref":"/zh/docs/patches/","tags":"","title":"补丁"}]